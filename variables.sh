# llamafile=Mistral-7B-Instruct-v0.3.Q4_0.llamafile
# llamafileurl="https://huggingface.co/Mozilla/Mistral-7B-Instruct-v0.3-llamafile/resolve/main/Mistral-7B-Instruct-v0.3.Q4_0.llamafile"

llamafile=Phi-3-mini-4k-instruct.Q2_K.llamafile
llamafileurl="https://huggingface.co/Mozilla/Phi-3-mini-4k-instruct-llamafile/resolve/main/Phi-3-mini-4k-instruct.Q2_K.llamafile"

llamafileimage="llamafile-on-lambda"
llamafiledir="./tmp/llamafile"
