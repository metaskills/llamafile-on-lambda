
# Llamafile on Lambda Demo (Phi-3 Mini 4k Instruct)

The llamafile project lets you distribute and run LLMs with a single file.

https://github.com/Mozilla-Ocho/llamafile





The Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties.




## Deploy

The following assumptions are made for the deploy environment:

1. An arm64 architecture. For example, a Mac with Apple Silicon.
2. 

```shell
./bin/deploy
```


```
------------------------------------------------------------------------------------
Outputs
------------------------------------------------------------------------------------
Key            LambdaFunctionUrl
Description    Lambda Function URL
Value          https://rqtkljzqpunkbwcwm4iysxpg3m0oxyze.lambda-url.us-east-1.on.aws/
------------------------------------------------------------------------------------
```

